{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b493f220-843b-4532-b015-bacf5f4d432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./lib/')\n",
    "\n",
    "with open('./lib/common_imports.py') as f:\n",
    "    exec(f.read())\n",
    "\n",
    "from hypothesis_test import pttest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3d3b37-76fb-41c3-ba28-09dd4a369608",
   "metadata": {},
   "source": [
    "# Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff38ebb3-d3cf-42de-8c58-711bae6d347d",
   "metadata": {},
   "source": [
    "To make decisions using data, we need to characterize the kinds of conclusions we can make. Classical hypothesis testing is concerned with deciding between two decisions (things get much harder if there’s more than two). The first, a null hypothesis is specified that represents the status quo. This hypothesis is usually labeled, $H_{0}$. This is what we assume by default. The alternative or\n",
    "research hypothesis is what we require evidence to conclude. This hypothesis is usually labeled, $H_{a}$ or sometimes $H_{1}$ (or some other number other than $0$). So to reiterate, the null hypothesis is assumed true and statistical evidence is required to reject it in favor of a research or alternative hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb7089f-bdd7-423b-a5dc-86d7388ae598",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c18051-699b-4946-b08c-e77e82430c5b",
   "metadata": {},
   "source": [
    "A respiratory disturbance index (RDI) of more than $30$ events / hour, say, is considered evidence of severe sleep disordered breathing (SDB). Suppose that in a sample of $100$ overweight subjects with\n",
    "other risk factors for sleep disordered breathing at a sleep clinic, the mean RDI was $32$ events / hour with a standard deviation of $10$ events / hour. We might want to test the hypothesis that\n",
    "\n",
    "$$\n",
    "H_{0} : \\mu = 30\n",
    "$$\n",
    "\n",
    "versus the hypothesis\n",
    "\n",
    "$$\n",
    "H_{a} : \\mu \\gt 30\n",
    "$$\n",
    "\n",
    "where $\\mu$ is the population mean RDI. Clearly, somehow we must figure out a way to decide between these hypotheses using the observed data, particularly the sample mean.\n",
    "\n",
    "Before we go through the specifics, let’s set up the central ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85429db-6751-4793-a7b3-bd2cdaaa94e3",
   "metadata": {},
   "source": [
    "## Types of errors in Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b55deb6-36f9-4925-8cc4-7e971a033bab",
   "metadata": {},
   "source": [
    "The alternative hypotheses are typically of the form of the true mean being $\\lt$, $\\gt$ or $\\neq$ to the hypothesized mean, such as $H_{a} : \\mu \\gt 30$ from our example. The null typically sharply specifies the mean, such as $H_{0} : \\mu = 30$ in our example. More complex null hypotheses are possible, but are typically covered in later courses.\n",
    "\n",
    "Note that there are four possible outcomes of our statistical decision process:\n",
    "\n",
    "| Truth | Decide | Result |\n",
    "|:-----|:--------|:------|\n",
    "|$H_{0}$ | $H_{0}$ | Correctly accepting null | \n",
    "|$H_{0}$ | $H_{a}$ | Type I error | \n",
    "|$H_{a}$ | $H_{a}$ | Correctly reject null | \n",
    "|$H_{a}$ | $H_{0}$ | Type II Error | \n",
    "\n",
    "We will perform hypothesis testing by forcing the probability of a Type I error to be small. This approach consequences, which we can discuss with an analogy to court cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea409b6-f569-4291-9571-ff7b810c84a0",
   "metadata": {},
   "source": [
    "### Discussion relative to court cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53baf0b5-6dfa-4b9e-a953-476fc9c14a88",
   "metadata": {},
   "source": [
    "Consider a court of law and a criminal case. The null hypothesis is that the defendant is innocent. The rules requires a standard on the available evidence to reject the null hypothesis (and the jury to convict). The standard is specified loosely in this case, such as convict if the defendant appears guilty \"Beyond reasonable doubt\". In statistics, we can be mathematically specific about our standard of evidence.\n",
    "\n",
    "Note the consequences of setting a standard. If we set a low standard, say convicting only if there circumstantial or greater evidence, then we would increase the percentage of innocent people convicted (type I errors). However, we would also increase the percentage of guilty people convicted (correctly rejecting the null).\n",
    "\n",
    "If we set a high standard, say the standard of convicting if the jury has \"No doubts whatsoever\", then we increase the the percentage of innocent people let free (correctly accepting the null) while we would also increase the percentage of guilty people let free (type II errors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60cb966-6b6d-4f80-86bc-6984700a9576",
   "metadata": {},
   "source": [
    "## Building up a standard of evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b8beae-d39d-41ba-bd12-0fd3a2381695",
   "metadata": {},
   "source": [
    "Consider our sleep example again. A reasonable strategy would reject the null hypothesis if the sample mean, $\\bar{X}$, was larger than some constant, say $C$. Typically, $C$ is chosen so that the probability of a Type I error, labeled $\\alpha$, is 0.05 (or some other relevant constant) To reiterate, $\\alpha$ = Type I error rate = Probability of rejecting the null hypothesis when, in fact, the null hypothesis is correct.\n",
    "\n",
    "Let’s see if we can figure out what $C$ has to be. The standard error of the mean is $10/\\sqrt{100} = 1$. Furthermore, under $H_{0}$ we know that $\\bar{X} \\sim \\mathcal{N}(30, 1)$ (at least approximately) via the CLT. We want to chose C so that:\n",
    "\n",
    "$$\n",
    "P(\\bar{X} \\gt C; H_{0}) = 0.05\n",
    "$$\n",
    "\n",
    "The $95^{th}$ percentile of a normal distribution is $1.645$ standard deviations from the mean. So, if $C$ is set $1.645$ standard deviations from the mean, we should be set since the probability of getting a sample mean that large is only $5\\%$. The $95^{th}$ percentile from a $\\mathcal{N}(30, 1)$ is:\n",
    "\n",
    "$$\n",
    "C = 30 + 1 \\times 1.645 = 31.645.\n",
    "$$\n",
    "\n",
    "So the rule \"Reject $H_{0}$ when $\\bar{X} \\geq 31.645$\" has the property that the probability of rejection is $5\\%$ when $H_{0}$ is true.\n",
    "\n",
    "In general, however, we don’t convert $C$ back to the original scale. Instead, we calculate how many standard errors the observed mean is from the hypothesized mean:\n",
    "\n",
    "$$\n",
    "Z = \\frac{\\bar{X} - \\mu_{0}}{s/ \\sqrt{n}}\n",
    "$$\n",
    "\n",
    "This is called a ***$Z$-score***. We can compare this statistic to standard normal quantiles. To reiterate, the $Z$-score is how many standard errors the sample mean is above the hypothesized mean. In our example:\n",
    "\n",
    "$$\n",
    "\\frac{32-30}{10/\\sqrt{100}} = 2\n",
    "$$\n",
    "\n",
    "Since $2$ is greater than $1.645$ we would reject. Setting the rule \"We reject if our $Z$-score is larger than 1.645\" controls the Type I error rate at $5\\%$. We could write out a general rule for this alternative hypothesis as reject whenever $\\sqrt{n}(\\bar{X} − \\mu_{0})/s > Z_{1−\\alpha}$ where $\\alpha$ is the desired Type I error rate. Because the Type I error rate was controlled to be small, if we reject we know that one of the following occurred:\n",
    "\n",
    "1. the null hypothesis is false,\n",
    "2. we observed an unlikely event in support of the alternative even though the null is true,\n",
    "3. our modeling assumptions are wrong.\n",
    "\n",
    "The third option can be difficult to check and at some level all bets are off depending on how wrong we are about our basic assumptions. So for this course, we speak of our conclusions under the assumption that our modeling choices (such as the iid sampling model) are correct, but do so wide eyed acknowledging the limitations of our approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cdfce3-07cc-4bad-9d91-05a5a5517f16",
   "metadata": {},
   "source": [
    "## General Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89393abf-c21c-4e12-9ae9-2964023dadaf",
   "metadata": {},
   "source": [
    "We developed our test for one possible alternatives. Here’s some general rules for the three most important alternatives.\n",
    "\n",
    "Consider the $Z$ test for $H_{0} : \\mu = \\mu_{0}$ versus: $H_{1} : \\mu \\lt \\mu_{0}$, $H_{2} : \\mu \\neq \\mu_{0}$, $H_{3} : \\mu \\gt \\mu_{0}$. Our test statistic\n",
    "\n",
    "$$\n",
    "TS = \\frac{\\bar{X} - \\mu_{0}}{S/\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "We reject the null hypothesis when:\n",
    "\n",
    "- $H_{1}: TS \\leq Z_{\\alpha} = -Z_{1-\\alpha}$\n",
    "- $H_{2}: |TS| \\geq Z_{1-\\alpha/2}$\n",
    "- $H_{3}: TS \\geq Z_{1-\\alpha/2}$\n",
    "\n",
    "respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41063efb-3363-4d6f-8a77-8f730da30af3",
   "metadata": {},
   "source": [
    "## Summary notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43640317-3d8f-4e01-b822-bdf561207f99",
   "metadata": {},
   "source": [
    "- We have fixed $\\alpha$ to be low, so if we reject $H_{0}$ (either our model is wrong) or there is a low probability that we have made an error.\n",
    "- We have not fixed the probability of a type II error, $\\beta$; therefore we tend to say \"Fail to reject H0\" rather than accepting $H_{0}$.\n",
    "- Statistical significance is no the same as scientific significance.\n",
    "- The region of $TS$ values for which you reject $H_{0}$ is called the rejection region.\n",
    "- The $Z$ test requires the assumptions of the CLT and for $n$ to be large enough for it to apply.\n",
    "- If $n$ is small, then a Gosset’s $t$ test is performed exactly in the same way, with the normal quantiles replaced by the appropriate Student’s $t$ quantiles and $n − 1$ df.\n",
    "- The probability of rejecting the null hypothesis when it is false is called power\n",
    "- Power is a used a lot to calculate sample sizes for experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555bacee-5107-403a-8349-16c926c9aad1",
   "metadata": {},
   "source": [
    "## Example reconsidered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5942bdad-967d-406d-a004-c303425ace08",
   "metadata": {},
   "source": [
    "Consider our example again. Suppose that $n = 16$ (rather than $100$). The statistic\n",
    "\n",
    "$$\n",
    "\\frac{\\bar{X} - 30}{s/\\sqrt{16}}\n",
    "$$\n",
    "\n",
    "follows a $t$ distribution with $15$ degrees of freedom under $H_{0}$.\n",
    "\n",
    "Under $H_{0}$, the probability that it is larger that the $95^{th}$ percentile of the $t$ distribution is $5\\%$. The $95^{th}%$ percentile of the $T$ distribution with 15 degrees of freedom is $1.7531$ (obtained via Python `scipy.stats.t.ppf(.95, 15)`). Assuming that everything but the sample size is the same, our test statistic is now $\\sqrt{16} (32-30)/10 = 0.8$. Since $0.8$ is not larger than $1.75$, we now fail to reject."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73c22eb-dc42-41f0-85c1-2cad5e6377a7",
   "metadata": {},
   "source": [
    "## Two sided tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f101af8c-ebe4-41ad-ba33-b9de2c1fe304",
   "metadata": {},
   "source": [
    "In many settings, we would like to reject if the true mean is *different* than the hypothesized, not just larger or smaller. I other words, we would reject the null hypothesis if in fact the sample mean was much larger or smaller than the hypothesized mean. In our example, we want to test the alternative $H_{a} : \\mu \\neq 30$. We will reject if the test statistic, $0.8$, is either too large or too small. Then we want the probability of rejecting under the null to be $5\\%$, split equally as $2.5\\%$ in the upper tail and $2.5\\%$ in the lower tail. \n",
    "\n",
    "Thus we reject if our test statistic is larger than `t.ppf(.975, 15)` or smaller than `t.ppf(.025, 15)`. This is the same as saying: reject if the absolute value of our statistic is larger than `t.ppf(0.975, 15)` = 2.1314. In this case, since our test statistic is $0.8$, which is smaller than $2.1314$, we fail to reject the two sided test (as well as the one sided test).\n",
    "\n",
    "If you fail to reject the one sided test, then you would fail to reject the two sided test. Because of its larger rejection region, two sided tests are the norm (even in settings where a one sided test makes more sense)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5c7a25-3010-4863-9215-7eef1b26c311",
   "metadata": {},
   "source": [
    "## T test in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d28067-37db-428d-9a96-2509b29f8a77",
   "metadata": {},
   "source": [
    "Let’s try the $t$ test on the pairs of fathers and sons in Galton’s data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e9c558d-3b74-405d-840e-88b8e06b958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "father_son = pd.read_csv('./data/father_son.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5fbaf0f-f08a-4b0b-be90-78b9a3233671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t One Sample t-test\n",
      "\n",
      "data: \tfather_son['sheight'] - father_son['fheight'], conf_int=0.95\n",
      "t = 11.789, df = 1077, p-value < 2.957226369228171e-30\n",
      "0.95 percent confidence interval:\n",
      "0.831 1.163\n",
      "sample esimates:\n",
      "mean of x\n",
      "0.997\n"
     ]
    }
   ],
   "source": [
    "pttest(father_son['sheight'] - father_son['fheight'], conf_int=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb99b0f-94ff-4404-b2dd-978f5523a1b2",
   "metadata": {},
   "source": [
    "## Connections with confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c1719c-0d79-4b4a-b3e1-90b6166ee912",
   "metadata": {},
   "source": [
    "Consider testing $H_{0} : \\mu = \\mu_{0}$ versus $H_{a} : \\mu \\neq \\mu_{0}$. Take the set of all possible values for which you fail to reject $H_{0}$, this set is a $(1-\\alpha)100 \\%$ confidence interval for $\\mu$.\n",
    "\n",
    "The same works in reverse; if a $(1-\\alpha)100 \\%$ interval contains $\\mu_{0}$, then we *fail to* reject $H_{0}$.\n",
    "\n",
    "In other words, two sided tests and confidence intervals agree. \n",
    "\n",
    "Consider the previous example. We were interested in whether or not, father's and son heights were equal. We got the answer that, no, they weren't as far as the hypnosis test was concerned. We also got the answer that the interval did not contain zero. You might be wondering whether or not those two statements could ever disagree and it turns out that no they can't. Checking whether or not munot is in the interval is identical to performing the two\n",
    "sided hypothesis test with the caveat that the alpha that you use for\n",
    "the interval, for the hypothesis test. Has to be equal to 1 minus alpha for\n",
    "the confidence interval. In other words if you\n",
    "construct a 95% interval, and just look for whether or\n",
    "not munot is in that interval and failed to reject if it's in that interval\n",
    "and reject if it's outside the interval. That is the same as performing that\n",
    "hypotheses test with an alpha level, with a type point error of exactly alpha. This is stated here in\n",
    "this slide by saying the confidence interval can be constructed\n",
    "as the set of all possible values for which you fail to reject\n",
    "a null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ed19ea-9d02-4bf7-aee6-1b99500b0991",
   "metadata": {},
   "source": [
    "## Two group intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c6be80-08bb-4a3a-8f7d-79fe02f128af",
   "metadata": {},
   "source": [
    "Doing group tests is now straightforward given that we’ve already covered independent group T intervals. Our rejection rules are the same, the only change is how the statistic is calculated. However, the form is familiar:\n",
    "\n",
    "$$\n",
    "\\frac{\\text{Estimate} - \\text{Hypothesized Value}}{\\text{Standard Error}}\n",
    "$$\n",
    "\n",
    "Consider now testing $H_{0} : \\mu_{1} = \\mu_{2}$. Our statistic is:\n",
    "\n",
    "$$\n",
    "\\frac{\\bar{X}_{1} - \\bar{X}_{2} - (\\mu_{1} - \\mu_{0})}{S_{p} \\sqrt{\\frac{1}{n_{1}} + \\frac{1}{n_{2}}}}\n",
    "$$\n",
    "\n",
    "For the equal variance case and\n",
    "\n",
    "$$\n",
    "\\frac{\\bar{X}_{1} - \\bar{X}_{2} - (\\mu_{1} - \\mu_{0})}{ \\sqrt{\\frac{S_{1}^{2}}{n_{1}} + \\frac{S_{2}^{2}}{n_{2}}}}\n",
    "$$\n",
    "\n",
    "For unequal variance.\n",
    "\n",
    "Let's just go through an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56906ca-eded-4616-a1a2-fbadc6fc2530",
   "metadata": {},
   "source": [
    "## Example `chickWeight` data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33823a17-17d9-4af5-838a-734bc65d92a3",
   "metadata": {},
   "source": [
    "Recall that we reformatted this data as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da2e6f4d-4153-4752-9598-481e31ec8c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t Two Sample t-test\n",
      "\n",
      "t = -2.725, df = 23.0, p-value = 0.01207\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "0.95 percent confidence interval:\n",
      "-108.15 -14.81\n",
      "sample estimates:\n",
      "mean in group 1 mean in group 2\n",
      "\t 136.19 \t 197.67\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "data = pd.read_csv('./data/wideCW.csv')\n",
    "\n",
    "wideCW14 = data[data['Diet'].isin([1,4])]\n",
    "d1 = wideCW14[wideCW14['Diet'] == 1]['gain']\n",
    "d4 = wideCW14[wideCW14['Diet'] == 4]['gain']\n",
    "\n",
    "def pindipendent_test(g1, g2, var_equal = True, confidence_level = 0.95):\n",
    "    \"\"\"\n",
    "    Function computing Two Sample T test\n",
    "    s1: np.array for the first sample\n",
    "    s2: np.array for the second sample\n",
    "    \"\"\"\n",
    "    print(\"\\n\\t Two Sample t-test\\n\")\n",
    "    k = ttest_ind(g1.dropna(), g2.dropna())\n",
    "    print(\"t = {}, df = {}, p-value = {}\".format(np.round(k.statistic, 3), np.round(k.df, 4), np.round(k.pvalue, 5)))\n",
    "    print(\"alternative hypothesis: true difference in means is not equal to 0\")\n",
    "    print(\"{} percent confidence interval:\".format(confidence_level))\n",
    "    print(\"{} {}\".format(np.round(k.confidence_interval(confidence_level=confidence_level).low,2), np.round(k.confidence_interval(confidence_level=confidence_level).high,2)))\n",
    "    print(\"sample estimates:\")\n",
    "    print(\"mean in group 1 mean in group 2\")\n",
    "    print(\"\\t {} \\t {}\".format(np.round(g1.mean(),2), np.round(g2.mean(),2)))\n",
    "\n",
    "pindipendent_test(d1, d4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6807611b-1513-4c20-a4de-61f137f3b2c9",
   "metadata": {},
   "source": [
    "## Exact binomial test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43b756e-dd8f-4cec-ab92-cabc789e8ce8",
   "metadata": {},
   "source": [
    "Recall this problem. Suppose a friend ha $8$ childrean, $7$ of which are girls and none are twins. Perform the relevan hypothesis test. \n",
    "\n",
    "$H_{0} : p = 0.5 \\text{ versus } H_{a} : p \\gt 0.5$\n",
    "\n",
    "What is the relevant rejection region so that the probability of rejecting is (less than) $5 \\%$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c698131-de8a-4ef4-9529-e787bad788e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejection region \t Type I error rate\n",
      "[0:8]           \t 1.0\n",
      "[1:8]           \t 0.99609375\n",
      "[2:8]           \t 0.96484375\n",
      "[3:8]           \t 0.85546875\n",
      "[4:8]           \t 0.63671875\n",
      "[5:8]           \t 0.36328125\n",
      "[6:8]           \t 0.14453125\n",
      "[7:8]           \t 0.03515625\n",
      "[8:8]           \t 0.00390625\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "print(\"Rejection region \\t Type I error rate\")\n",
    "for i in np.arange(8,-1,-1):\n",
    "    print(\"[{}:8]           \\t {}\".format( 8-i, binom.cdf(i,8, p =0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b62ccb7-d15d-4f7c-a8ef-39fb4e3d5087",
   "metadata": {},
   "source": [
    "Thus if we reject under 7 or 8 girls, we will have a less than $5 \\%$ chance of rejecting under the null hypothesis.\n",
    "\n",
    "It’s impossible to get an exact 5% level test for this case due to the discreteness of the binomial. The closest is the rejection region [7 : 8]. Further note that an alpha level lower than 0.0039 is not attainable. For larger sample sizes, we could do a normal approximation. \n",
    "\n",
    "Extended this test to two sided test isn’t obvious. Given a way to do two sided tests, we could take the set of values of $p_{0}$ for which we fail to reject to get an exact binomial confidence interval (called the *Clopper/Pearson interval*, by the way). We’ll cover two sided versions of this test when we cover P-values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
